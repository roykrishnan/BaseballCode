{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "265cbe2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-02T00:13:33.660161Z",
     "iopub.status.busy": "2024-10-02T00:13:33.659663Z",
     "iopub.status.idle": "2024-10-02T00:13:38.494170Z",
     "shell.execute_reply": "2024-10-02T00:13:38.492562Z"
    },
    "papermill": {
     "duration": 4.846625,
     "end_time": "2024-10-02T00:13:38.496293",
     "exception": true,
     "start_time": "2024-10-02T00:13:33.649668",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pybaseball'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcb\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpybaseball\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpybaseball\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pybaseball'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import catboost as cb\n",
    "import pybaseball\n",
    "from pybaseball.cache import cache\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "cache.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5885b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the original training and test data\n",
    "train = pd.read_csv('cleaned_data/train_clean.csv')\n",
    "test = pd.read_csv('cleaned_data/test_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2796235",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5d126",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train['outcome'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da461719",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.drop('outcome',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee0be0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.concat([train,test],axis=1).duplicated().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63d305",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cat_features = test.select_dtypes(include='O').columns.tolist()\n",
    "initial_features = list(test.columns)\n",
    "for feature in initial_features:\n",
    "    if feature in cat_features:    \n",
    "        categories = sorted(set(test[feature].dropna()))\n",
    "        dtype = pd.CategoricalDtype(categories=categories, ordered=False)\n",
    "        print(sum(~np.isin(test[feature].unique(),train[feature].unique())))\n",
    "        print(test[feature].unique()[~np.isin(test[feature].unique(),train[feature].unique())])\n",
    "        train.loc[~train[feature].isin(categories),feature] = np.nan\n",
    "        train[feature] = train[feature].astype(dtype)     \n",
    "        test[feature] = test[feature].astype(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40670db2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_cols = ['game_year','game_type']\n",
    "target = 'outcome_code'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fee2b57",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.drop(drop_cols,axis=1,inplace=True)\n",
    "test.drop(drop_cols,axis=1,inplace=True)\n",
    "cat_features = test.select_dtypes(include='category').columns.tolist()\n",
    "initial_features = list(test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089b6780",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1,2, figsize=(8,3))\n",
    "ax = axs.ravel()\n",
    "vc = train[target].value_counts()/len(train)\n",
    "ax[0].bar(vc.index,vc,color='lightblue')\n",
    "ax[0].bar_label(ax[0].containers[0], label_type='center', color='red')\n",
    "ax[0].yaxis.set_major_formatter('{x:.0%}')\n",
    "vc = train[target].value_counts()\n",
    "ax[1].pie(vc,labels=vc.index,autopct='%.0f%%')\n",
    "plt.title('Targets');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec6bc14",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "# Function to get additional data using pybaseball\n",
    "def get_additional_data(existing_uids):\n",
    "    HIT_COLS = [\"home_run\", \"triple\", \"double\", \"single\"]\n",
    "    \n",
    "    def spray_angle(hc_x, hc_y):\n",
    "        return np.arctan2(hc_x - 125.42, 198.27 - hc_y)\n",
    "    \n",
    "    additional_data = pybaseball.statcast(start_dt=\"2024-07-17\", end_dt=datetime.datetime.now().date().strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "    additional_data = additional_data[additional_data['type'] == 'X']\n",
    "    additional_data['is_lhp'] = additional_data['p_throws'] == 'L'\n",
    "    additional_data['is_lhb'] = additional_data['stand'] == 'L'\n",
    "    additional_data['outcome'] = additional_data['events'].map(\n",
    "        lambda x: 'out' if x not in HIT_COLS else x)\n",
    "    additional_data['outcome_code'] = additional_data['outcome'].map(\n",
    "        {'out': 0, 'single': 1, 'double': 2, 'triple': 3, 'home_run': 4})\n",
    "    additional_data['is_top'] = additional_data['inning_topbot'] == 'TOP'\n",
    "    additional_data['spray_angle'] = np.where(\n",
    "        additional_data['is_lhb'],\n",
    "        -spray_angle(additional_data['hc_x'], additional_data['hc_y']),\n",
    "        spray_angle(additional_data['hc_x'], additional_data['hc_y'])\n",
    "    )\n",
    "    \n",
    "    additional_data = additional_data[additional_data['outcome'].isin(HIT_COLS)]\n",
    "    \n",
    "    # Generate new unique UIDs\n",
    "    new_uids = [str(uuid.uuid4()) for _ in range(len(additional_data))]\n",
    "    additional_data['uid'] = new_uids\n",
    "    \n",
    "    # Select only the columns present in the original training data\n",
    "    selected_columns = [col for col in train.columns if col in additional_data.columns]\n",
    "    \n",
    "    return additional_data[selected_columns]\n",
    "\n",
    "# Get the existing UIDs from the original training data\n",
    "existing_uids = set(train['uid'])\n",
    "\n",
    "# Combine original and additional data\n",
    "additional_data = get_additional_data(existing_uids)\n",
    "all_train = pd.concat([train, additional_data], ignore_index=True)\n",
    "\n",
    "# Verify that we have the correct number of unique UIDs\n",
    "print(f\"Total rows in combined dataset: {len(all_train)}\")\n",
    "print(f\"Number of unique UIDs: {all_train['uid'].nunique()}\")\n",
    "\n",
    "# Continue with your existing preprocessing steps\n",
    "cat_features = test.select_dtypes(include='object').columns.tolist()\n",
    "initial_features = list(test.columns)\n",
    "for feature in initial_features:\n",
    "    if feature in cat_features:    \n",
    "        categories = sorted(set(test[feature].dropna()))\n",
    "        dtype = pd.CategoricalDtype(categories=categories, ordered=False)\n",
    "        print(sum(~np.isin(test[feature].unique(), all_train[feature].unique())))\n",
    "        print(test[feature].unique()[~np.isin(test[feature].unique(), all_train[feature].unique())])\n",
    "        all_train.loc[~all_train[feature].isin(categories), feature] = np.nan\n",
    "        all_train[feature] = all_train[feature].astype(dtype)     \n",
    "        test[feature] = test[feature].astype(dtype)\n",
    "\n",
    "target = 'outcome_code'\n",
    "\n",
    "cat_features = test.select_dtypes(include='category').columns.tolist()\n",
    "initial_features = list(test.columns)\n",
    "\n",
    "# Visualization\n",
    "_, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "ax = axs.ravel()\n",
    "vc = all_train[target].value_counts(normalize=True)\n",
    "ax[0].bar(vc.index, vc, color='lightblue')\n",
    "ax[0].bar_label(ax[0].containers[0], label_type='center', color='red')\n",
    "ax[0].yaxis.set_major_formatter('{x:.0%}')\n",
    "vc = all_train[target].value_counts()\n",
    "ax[1].pie(vc, labels=vc.index, autopct='%.0f%%')\n",
    "plt.title('Targets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537d4e6b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # First set of features\n",
    "    df['pitch_speed_diff'] = df['release_speed'] - df['effective_speed']\n",
    "    df['horizontal_movement'] = df['pfx_x'] * df['release_extension']\n",
    "    df['vertical_movement'] = df['pfx_z'] * df['release_extension']\n",
    "    df['pitch_location'] = np.sqrt(df['plate_x']**2 + df['plate_z']**2)\n",
    "    df['count_pressure'] = df['balls'] - df['strikes'] + 1\n",
    "    df['bat_pitch_speed_ratio'] = df['bat_speed'] / df['release_speed']\n",
    "    df['swing_efficiency'] = df['bat_speed'] / df['swing_length']\n",
    "    df['movement_complexity'] = np.sqrt(df['pfx_x']**2 + df['pfx_z']**2)\n",
    "    df['release_angle'] = np.arctan2(df['release_pos_z'], df['release_pos_x'])\n",
    "    df['approach_angle'] = np.arctan2(df['vz0'], np.sqrt(df['vx0']**2 + df['vy0']**2))\n",
    "    df['spin_efficiency'] = np.abs(np.sin(np.radians(df['spin_axis'])))\n",
    "    df['magnus_effect'] = df['release_spin_rate'] * df['movement_complexity']\n",
    "    df['break_time'] = df['release_extension'] / df['effective_speed']\n",
    "    df['tunneling_time'] = 0.15 * df['release_speed'] / (df['movement_complexity'] + 1e-5)  # Add small constant to avoid division by zero\n",
    "    df['stance_advantage'] = ((df['is_lhp'] == 1) & (df['is_lhb'] == 0)) | ((df['is_lhp'] == 0) & (df['is_lhb'] == 1))\n",
    "    df['pitch_speed_change'] = df.groupby('pitch_number')['release_speed'].diff().fillna(0)\n",
    "    df['horizontal_change'] = df.groupby('pitch_number')['pfx_x'].diff().fillna(0)\n",
    "    df['vertical_change'] = df.groupby('pitch_number')['pfx_z'].diff().fillna(0)\n",
    "    df['baserunner_pressure'] = df['on_1b'].fillna(0) + 2*df['on_2b'].fillna(0) + 3*df['on_3b'].fillna(0)\n",
    "    df['late_inning_pressure'] = (df['inning'] >= 7).astype(int)\n",
    "    df['release_x_deviation'] = df['release_pos_x'] - df['release_pos_x'].mean()\n",
    "    df['release_z_deviation'] = df['release_pos_z'] - df['release_pos_z'].mean()\n",
    "    df['relative_height'] = (df['plate_z'] - df['sz_bot']) / (df['sz_top'] - df['sz_bot'])\n",
    "    \n",
    "    # Handle NA values for is_strike\n",
    "    df['is_strike'] = (\n",
    "        (df['plate_x'].between(-0.7083, 0.7083)) & \n",
    "        (df['relative_height'].between(0, 1))\n",
    "    ).fillna(False).astype(int)\n",
    "    \n",
    "    df['contact_quality'] = df['bat_speed'] * np.cos(np.radians(df['spray_angle']))\n",
    "\n",
    "    # New hitting-focused features\n",
    "    df['bat_to_pitch_speed_ratio'] = df['bat_speed'] / df['effective_speed']\n",
    "    df['swing_plane_efficiency'] = np.cos(np.radians(df['spray_angle'])) / (df['swing_length'] + 1e-5)\n",
    "    df['contact_zone'] = np.arctan2(df['plate_z'], df['plate_x']) + df['spray_angle']\n",
    "    df['swing_decision_time'] = df['effective_speed'] / (df['swing_length'] + 1e-5)\n",
    "    df['power_potential'] = df['bat_speed'] * np.abs(np.sin(np.radians(df['spray_angle'])))\n",
    "    df['plate_discipline_index'] = df['is_strike'] * df['swing_efficiency']\n",
    "    df['bat_control'] = df['bat_speed'] / (df['swing_length'] + 1e-5)\n",
    "    df['exit_velocity_estimate'] = (df['bat_speed'] + df['effective_speed']) * 0.5\n",
    "    df['launch_angle_estimate'] = df['spray_angle'] * 0.6\n",
    "    df['sweet_spot_probability'] = 1 / (1 + np.exp(-(df['bat_speed'] - 70) / 10)) * (1 - np.abs(df['swing_length'] - 24) / 24)\n",
    "\n",
    "    # Additional features\n",
    "    df['exit_velocity_launch_angle_ratio'] = df['exit_velocity_estimate'] / (df['launch_angle_estimate'].abs() + 1)\n",
    "    df['swing_efficiency_score'] = df['swing_efficiency'] * df['bat_control'] * df['sweet_spot_probability']\n",
    "    df['pitch_complexity'] = df['release_speed'] * df['spin_efficiency'] * (df['vertical_movement'].abs() + 1)\n",
    "    df['batter_readiness'] = df['plate_discipline_index'] * df['swing_decision_time']\n",
    "    df['contact_quality_score'] = df['exit_velocity_estimate'] * df['sweet_spot_probability'] * df['bat_speed']\n",
    "    df['pitch_location_effectiveness'] = df['pitch_location'] * df['is_strike'] * (1 - df['plate_discipline_index'])\n",
    "    df['count_pressure_impact'] = df['count_pressure'] * (df['balls'] - df['strikes'] + 3)\n",
    "    df['batter_power_index'] = df['power_potential'] * df['exit_velocity_estimate'] * df['bat_speed']\n",
    "    df['pitch_deception_score'] = df['effective_speed'] / df['release_speed'] * df['spin_efficiency']\n",
    "    df['batter_contact_ability'] = df['bat_control'] * df['contact_zone'] * df['swing_plane_efficiency']\n",
    "    df['pitch_movement_complexity'] = (df['pfx_z'].abs() + df['vertical_change'].abs()) * df['spin_efficiency']\n",
    "    df['batter_pitcher_matchup'] = df['stance_advantage'] * df['relative_height'] * df['pitch_location_effectiveness']\n",
    "    df['swing_aggressiveness'] = df['swing_length'] * df['bat_speed'] / (df['swing_decision_time'] + 1e-5)\n",
    "    df['pitch_bat_speed_differential'] = df['release_speed'] - df['bat_speed']\n",
    "    df['exit_velocity_pitch_speed_ratio'] = df['exit_velocity_estimate'] / df['release_speed']\n",
    "    df['vertical_approach_effectiveness'] = df['approach_angle'] * df['launch_angle_estimate'] * df['exit_velocity_estimate']\n",
    "    df['horizontal_spray_effectiveness'] = df['spray_angle'].abs() * df['exit_velocity_estimate']\n",
    "    df['strike_zone_coverage'] = (df['sz_top'] - df['sz_bot']) * df['plate_discipline_index']\n",
    "    df['pitch_location_accuracy'] = 1 - (((df['plate_x']**2 + df['plate_z']**2)**0.5) / ((2.5**2 + 2.5**2)**0.5))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911d754f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the feature addition to the dataframes\n",
    "all_train = add_features(all_train)\n",
    "test = add_features(test)\n",
    "\n",
    "# Display some information about the new features\n",
    "print(f\"Number of features after engineering: {all_train.shape[1]}\")\n",
    "print(\"\\nNew features added:\")\n",
    "new_features = set(all_train.columns) - set(initial_features)\n",
    "print(\", \".join(new_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f23e5d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = all_train.drop(['outcome_code', 'uid'], axis=1)  # Assuming 'uid' is not a feature\n",
    "y = all_train['outcome_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9f86dc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Identify categorical features\n",
    "cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Handle NaN values in categorical features\n",
    "for feature in cat_features:\n",
    "    # For training data\n",
    "    if X[feature].dtype.name == 'category':\n",
    "        # Add 'Unknown' to categories if it's not already there\n",
    "        if 'Unknown' not in X[feature].cat.categories:\n",
    "            X[feature] = X[feature].cat.add_categories('Unknown')\n",
    "        X[feature] = X[feature].fillna('Unknown')\n",
    "    else:\n",
    "        X[feature] = X[feature].fillna('Unknown').astype('category')\n",
    "    \n",
    "    # For test data\n",
    "    if test[feature].dtype.name == 'category':\n",
    "        # Ensure all categories from training data are in test data\n",
    "        test[feature] = test[feature].cat.add_categories(X[feature].cat.categories.difference(test[feature].cat.categories))\n",
    "        if 'Unknown' not in test[feature].cat.categories:\n",
    "            test[feature] = test[feature].cat.add_categories('Unknown')\n",
    "        test[feature] = test[feature].fillna('Unknown')\n",
    "    else:\n",
    "        test[feature] = test[feature].fillna('Unknown').astype('category')\n",
    "    \n",
    "    # Ensure both train and test have the same categories\n",
    "    all_categories = X[feature].cat.categories.union(test[feature].cat.categories)\n",
    "    X[feature] = X[feature].cat.set_categories(all_categories)\n",
    "    test[feature] = test[feature].cat.set_categories(all_categories)\n",
    "\n",
    "# Handle NaN values in numerical features\n",
    "# Separate integer and float features\n",
    "int_features = X.select_dtypes(include=['int64']).columns.tolist()\n",
    "float_features = X.select_dtypes(include=['float64']).columns.tolist()\n",
    "\n",
    "# Convert integer features to float to accommodate mean values\n",
    "X[int_features] = X[int_features].astype('float64')\n",
    "test[int_features] = test[int_features].astype('float64')\n",
    "\n",
    "# Combine all numerical features as float\n",
    "num_features = int_features + float_features\n",
    "\n",
    "# Fill NaN values with the mean from the training set\n",
    "X[num_features] = X[num_features].fillna(X[num_features].mean())\n",
    "test[num_features] = test[num_features].fillna(X[num_features].mean())  # Use training mean for test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c48e3ae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Double-check for any remaining NaN values\n",
    "assert X.isnull().sum().sum() == 0, \"There are still NaN values in the training set\"\n",
    "assert test.isnull().sum().sum() == 0, \"There are still NaN values in the test set\"\n",
    "\n",
    "# Print info about the datasets\n",
    "print(X.info())\n",
    "print(\"\\n\")\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733a4efa",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import catboost as cb\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9620df",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Categorical Features:\", cat_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593f8c06",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "def custom_cross_validate(model, X, y, cv, cat_features):\n",
    "    \"\"\"\n",
    "    Performs cross-validation for CatBoostClassifier with categorical features.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The CatBoostClassifier instance.\n",
    "    - X: Feature matrix (pandas DataFrame).\n",
    "    - y: Target vector (pandas Series).\n",
    "    - cv: Cross-validation splitter (e.g., StratifiedKFold instance).\n",
    "    - cat_features: List of categorical feature indices or names.\n",
    "\n",
    "    Returns:\n",
    "    - oof_preds: Out-of-fold predictions as a NumPy array.\n",
    "    \"\"\"\n",
    "    oof_preds = np.zeros((len(X), len(y.unique())))\n",
    "    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Fit the model with categorical features\n",
    "        model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=(X_val, y_val),\n",
    "            early_stopping_rounds=50,\n",
    "            verbose=False,\n",
    "            cat_features=cat_features\n",
    "        )\n",
    "        \n",
    "        # Predict probabilities for the validation set\n",
    "        oof_preds[val_idx] = model.predict_proba(X_val)\n",
    "        \n",
    "        # Calculate and print AUC for the current fold\n",
    "        score = roc_auc_score(y_val, oof_preds[val_idx], multi_class='ovr')\n",
    "        print(f\"Fold {fold + 1} - AUC: {score:.4f}\")\n",
    "    \n",
    "    return oof_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1165b9e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters for CatBoost\n",
    "    cb_params = {\n",
    "        'iterations': trial.suggest_int('cb_iterations', 500, 2000),\n",
    "        'learning_rate': trial.suggest_loguniform('cb_learning_rate', 0.01, 0.3),\n",
    "        'depth': trial.suggest_int('cb_depth', 4, 10),\n",
    "        'l2_leaf_reg': trial.suggest_int('cb_l2_leaf_reg', 1, 10),\n",
    "        'bagging_temperature': trial.suggest_uniform('cb_bagging_temperature', 0, 1),\n",
    "        'random_state': 42,\n",
    "        'eval_metric': 'AUC',\n",
    "        'verbose': False,\n",
    "    }\n",
    "    \n",
    "    # Initialize CatBoost with suggested hyperparameters\n",
    "    cb_model = cb.CatBoostClassifier(**cb_params)\n",
    "    \n",
    "    # Perform cross-validation for CatBoost\n",
    "    cb_oof = custom_cross_validate(cb_model, X, y, kf, cat_features)\n",
    "    cb_score = roc_auc_score(y, cb_oof, multi_class='ovr')\n",
    "    print(f\"CatBoost OOF AUC: {cb_score:.4f}\")\n",
    "    \n",
    "    # Suggest hyperparameters for XGBoost\n",
    "    xgb_params = {\n",
    "        'n_estimators': trial.suggest_int('xgb_n_estimators', 100, 500),\n",
    "        'learning_rate': trial.suggest_loguniform('xgb_learning_rate', 0.01, 0.3),\n",
    "        'max_depth': trial.suggest_int('xgb_max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_uniform('xgb_subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('xgb_colsample_bytree', 0.5, 1.0),\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': len(y.unique()),\n",
    "        'random_state': 42,\n",
    "        'verbosity': 0\n",
    "    }\n",
    "    \n",
    "    # Initialize XGBoost with suggested hyperparameters\n",
    "    xgb_model = xgb.XGBClassifier(**xgb_params)\n",
    "\n",
    "    # Use cross_val_predict for out-of-fold predictions\n",
    "    ensemble_oof = cross_val_predict(xgb_model, cb_oof, y, cv=kf, method='predict_proba')\n",
    "    ensemble_score = roc_auc_score(y, ensemble_oof, multi_class='ovr')\n",
    "    print(f\"XGBoost Ensemble OOF AUC: {ensemble_score:.4f}\")\n",
    "    \n",
    "    return ensemble_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e63eb17",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an Optuna study\n",
    "study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\n",
    "# Optimize the study\n",
    "study.optimize(objective, n_trials=10, timeout=3600)  # Adjust n_trials and timeout as needed\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best Hyperparameters:\")\n",
    "for key, value in best_params.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c40c7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# 5. Training Final Models with Best Hyperparameters\n",
    "# ---------------------------\n",
    "\n",
    "# Define the best CatBoost model\n",
    "best_cb_params = {\n",
    "    'iterations': best_params.get('cb_iterations', 1418),\n",
    "    'learning_rate': best_params.get('cb_learning_rate', .01607712851203988),\n",
    "    'depth': best_params.get('cb_depth', 6),\n",
    "    'l2_leaf_reg': best_params.get('cb_l2_leaf_reg', 4),\n",
    "    'bagging_temperature': best_params.get('cb_bagging_temperature', 0.45606998421703593),\n",
    "    'random_state': 42,\n",
    "    'eval_metric': 'AUC',\n",
    "    'verbose': False,\n",
    "    # 'cat_features' is removed from here\n",
    "}\n",
    "\n",
    "cb_model = cb.CatBoostClassifier(**best_cb_params)\n",
    "\n",
    "# Train the best CatBoost model using the custom cross-validation\n",
    "print(\"Training optimized CatBoost model...\")\n",
    "cb_oof = custom_cross_validate(cb_model, X, y, kf, cat_features)\n",
    "cb_score = roc_auc_score(y, cb_oof, multi_class='ovr')\n",
    "print(f\"Optimized CatBoost OOF AUC: {cb_score:.4f}\")\n",
    "\n",
    "# Define the best XGBoost model\n",
    "best_xgb_params = {\n",
    "    'n_estimators': best_params.get('xgb_n_estimators', 414),\n",
    "    'learning_rate': best_params.get('xgb_learning_rate', 0.019721610970574007),\n",
    "    'max_depth': best_params.get('xgb_max_depth', 7),\n",
    "    'subsample': best_params.get('xgb_subsample', .7962072844310213),\n",
    "    'colsample_bytree': best_params.get('xgb_colsample_bytree', .5232252063599989),\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': len(y.unique()),\n",
    "    'random_state': 42,\n",
    "    'verbosity': 0\n",
    "}\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(**best_xgb_params)\n",
    "\n",
    "# Train the XGBoost ensemble model using cross_val_predict\n",
    "print(\"Training optimized XGBoost Ensemble...\")\n",
    "ensemble_oof = cross_val_predict(\n",
    "    xgb_model, \n",
    "    cb_oof, \n",
    "    y, \n",
    "    cv=kf, \n",
    "    method='predict_proba'\n",
    ")\n",
    "ensemble_score = roc_auc_score(y, ensemble_oof, multi_class='ovr')\n",
    "print(f\"Optimized XGBoost Ensemble OOF AUC: {ensemble_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d17ce6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Final predictions on test set\n",
    "print(\"Making final predictions on the test set...\")\n",
    "cb_model.fit(X, y, cat_features=cat_features, verbose=False)\n",
    "cb_test_preds = cb_model.predict_proba(test.drop('uid', axis=1))\n",
    "\n",
    "# Train XGBoost on the full OOF predictions\n",
    "xgb_model.fit(cb_oof, y)\n",
    "final_preds = xgb_model.predict_proba(cb_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7553fe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare submission\n",
    "submission = pd.DataFrame({\n",
    "    'uid': test['uid'],\n",
    "    'out': final_preds[:, 0],\n",
    "    'single': final_preds[:, 1],\n",
    "    'double': final_preds[:, 2],\n",
    "    'triple': final_preds[:, 3],\n",
    "    'home_run': final_preds[:, 4]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a510487c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9257194,
     "sourceId": 83504,
     "sourceType": "competition"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11.538795,
   "end_time": "2024-10-02T00:13:42.085310",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-02T00:13:30.546515",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
